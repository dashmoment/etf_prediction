{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import os\n",
    "verbose_state = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_c(print_content, verbose = verbose_state):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(print_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read pickle data\n",
      "Finish read pickle data\n",
      "Process data\n"
     ]
    }
   ],
   "source": [
    "print_c(\"Read pickle data\")\n",
    "\n",
    "f = open('./Data/all_data.pkl', 'rb')\n",
    "_ = pickle.load(f)\n",
    "_ = pickle.load(f)\n",
    "process_data = pd.DataFrame(pickle.load(f))\n",
    "\n",
    "print_c(\"Finish read pickle data\")\n",
    "print_c(\"Process data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select date\n",
    "mask = (process_data.columns >= '20130102') & (process_data.columns < '20140302')\n",
    "select_date = process_data.iloc[:,mask]\n",
    "\n",
    "#drop NA\n",
    "select_date = select_date.dropna()\n",
    "\n",
    "for c in select_date.columns:    \n",
    "    for idx in select_date[c].index:\n",
    "        select_date[c].loc[idx] = select_date[c].loc[idx].drop(['ID', 'Date','name','trade']).tolist()\n",
    "        \n",
    "#make a stck_df to np_array \n",
    "stock_1101 = select_date.loc['1101']\n",
    "stock_1101_np = np.vstack(np.array(stock_1101))\n",
    "\n",
    "'''\n",
    "#make multiple stck_df to np_array        \n",
    "stocks = ['1101','1102']\n",
    "stock_1101_02 = select_date.loc[stocks]\n",
    "stock_1101_02_np = np.hstack(np.array(stock_1101_02))\n",
    "stock_1101_02_np = np.vstack(np.array(stock_1101_02_np))\n",
    "stock_1101_02_np_r = np.split(stock_1101_02_np, len(stocks))\n",
    "stock_1101_02_np_r = np.dstack(stock_1101_02_np_r)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single stock == multiple_stock: True\n"
     ]
    }
   ],
   "source": [
    "#Check process is correct\n",
    "print_c(\"single stock == multiple_stock: {}\".format(np.equal(stock_1101_np, stock_1101_02_np_r[:,:,0]).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start build RNN model\n"
     ]
    }
   ],
   "source": [
    "#Prepare for rnn\n",
    "print_c(\"Start build RNN model\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single stock\n",
    "\n",
    "data = stock_1101_np\n",
    "train_step = 12\n",
    "test_step = 5\n",
    "all_step = train_step + test_step\n",
    "data_size = 50\n",
    "n_inputs = data.shape[-1]\n",
    "n_hidden_units = 10\n",
    "n_output = 3\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_portion = int(0.8*len(data))\n",
    "train, val = np.split(data, [train_portion])\n",
    "\n",
    "def gen_train_val_set(data, total_time_step):\n",
    "\n",
    "    data_set = np.zeros((len(data)-total_time_step, total_time_step, data.shape[-1]))\n",
    "\n",
    "    for i in range(len(data)-total_time_step):\n",
    "\n",
    "        tmp = data[i:i+total_time_step,:]\n",
    "        data_set[i] = tmp\n",
    "        \n",
    "    return data_set\n",
    "\n",
    "total_time_step = train_step + test_step\n",
    "train_set = gen_train_val_set(train, total_time_step)\n",
    "test_set = gen_train_val_set(val, total_time_step)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 17, 4)\n",
      "(40, 17, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_set))\n",
    "print(np.shape(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse = True\n",
    "\n",
    "def default_init(seed):\n",
    "    # replica of tf.glorot_uniform_initializer(seed=seed)\n",
    "    return tf.contrib.layers.variance_scaling_initializer(factor=1.0,\n",
    "                                               mode=\"FAN_AVG\",\n",
    "                                               uniform=True,\n",
    "                                               seed=seed)\n",
    "\n",
    "with tf.variable_scope('cell') as scope:\n",
    "    # Define weights  \n",
    "    if reuse: scope.reuse_variables()\n",
    "    weights = {  \n",
    "        # (28, 128)  \n",
    "        'in': tf.get_variable(\"Win\", [data.shape[-1], n_hidden_units], initializer = tf.zeros_initializer()),\n",
    "        # (128, 10)  \n",
    "        'out': tf.get_variable(\"Wout\", [n_hidden_units, n_output], initializer = tf.zeros_initializer())\n",
    "    }  \n",
    "\n",
    "  \n",
    "    biases = {  \n",
    "        # (128, )  \n",
    "        'in': tf.get_variable('b_in', [n_hidden_units, ], initializer = tf.constant_initializer(0.1)),  \n",
    "        # (10, )  \n",
    "        'out': tf.get_variable('b_out', [n_output, ],initializer = tf.constant_initializer(0.1))  \n",
    "    }  \n",
    "    \n",
    "\n",
    "def encoder(X, weights, biases):  \n",
    "    # hidden layer for input to cell  \n",
    "    ########################################  \n",
    "  \n",
    "    # transpose the inputs shape from  \n",
    "    # X ==> (128 batch * 28 steps, 28 inputs)  \n",
    "    X = tf.reshape(X, [-1, n_inputs])  \n",
    "  \n",
    "    # into hidden  \n",
    "    # X_in = (batch * time_steps, n_hidden_units)  \n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']  \n",
    "    # X_in ==> (batch, 28 time_steps, n_hidden_units)  \n",
    "    X_in = tf.reshape(X_in, [-1, train_step, n_hidden_units]) \n",
    "    \n",
    "    with tf.variable_scope('encoder') as scope:\n",
    "        if reuse: scope.reuse_variables()\n",
    "        cell = tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(n_hidden_units)\n",
    "        init_state = cell.zero_state(batch_size, dtype=tf.float32) \n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False,scope='cell')  \n",
    "    \n",
    "    return outputs, final_state\n",
    "\n",
    "def decoder(previous_y, state):\n",
    "    \n",
    "    predict_days = 5\n",
    "    with tf.variable_scope('decoder') as scope:\n",
    "            if reuse: scope.reuse_variables()\n",
    "            cell = tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(n_hidden_units)\n",
    "    \n",
    "    def cond_fn(time, prev_output, prev_state, array_targets: tf.TensorArray, array_outputs: tf.TensorArray):\n",
    "        return time < predict_days\n",
    "    \n",
    "    def project_fn(tensor):\n",
    "        with tf.variable_scope('decoder_output_proj') as scope:\n",
    "            if reuse: scope.reuse_variables()\n",
    "            d_layer = tf.layers.dense(tensor, 1, name='decoder_output_proj', kernel_initializer=default_init(0))\n",
    "        return d_layer\n",
    "\n",
    "    def loop_fn(time, prev_output, prev_state, array_targets: tf.TensorArray, array_outputs: tf.TensorArray):\n",
    "        \n",
    "        next_input = prev_output\n",
    "        \n",
    "        with tf.variable_scope('decoder') as scope:\n",
    "            if reuse: scope.reuse_variables()\n",
    "            output, state = cell(next_input, prev_state)\n",
    "            projected_output = project_fn(output)\n",
    "            #projected_output = output\n",
    "        \n",
    "        array_outputs = array_outputs.write(time, output)\n",
    "        array_targets = array_targets.write(time, projected_output)\n",
    "        \n",
    "        return time + 1, projected_output, state, array_targets, array_outputs\n",
    "    \n",
    "    loop_init = [tf.constant(0, dtype=tf.int32), #time\n",
    "                     project_fn(previous_y), \n",
    "                     state,\n",
    "                     tf.TensorArray(dtype=tf.float32, size=predict_days),\n",
    "                     tf.TensorArray(dtype=tf.float32, size=predict_days) ]\n",
    "        \n",
    "    _, _, _, targets_ta, outputs_ta = tf.while_loop(cond_fn, loop_fn, loop_init)\n",
    "    \n",
    "    targets = targets_ta.stack()\n",
    "    # [time, batch_size, 1] -> [time, batch_size]\n",
    "    targets = tf.squeeze(targets, axis=-1)\n",
    "    raw_outputs = outputs_ta.stack()\n",
    "    \n",
    "    targets = tf.transpose(targets, (1,0))\n",
    "    raw_outputs = tf.transpose(raw_outputs, (1,0,2))\n",
    "\n",
    "\n",
    "    return targets, raw_outputs\n",
    "\n",
    "# tf Graph input  \n",
    "x = tf.placeholder(tf.float32, [None, train_step, data.shape[-1]])  \n",
    "enc, state  = encoder(x, weights, biases)\n",
    "dec, raw_dec = decoder(enc[:,-1], state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, [None, test_step])  \n",
    "loss = tf.losses.mean_squared_error(\n",
    "    y,\n",
    "    dec,\n",
    "    )\n",
    "\n",
    "with tf.variable_scope('optimizer') as scope:\n",
    "    if reuse: scope.reuse_variables()\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train_summary'):\n",
    "    tf.summary.scalar('l2loss', loss, collections=['train'])\n",
    "    merged_summary_train = tf.summary.merge_all('train')     \n",
    "    \n",
    "with tf.name_scope('validatin_summary'):\n",
    "    tf.summary.scalar('l2loss', loss, collections=['validatin'])\n",
    "    merged_summary_val = tf.summary.merge_all('validatin') \n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter('./data/log', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-165-0a7802896c6f>:5: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(data_set) < cur_index+batch_size, \"batch index out of range\")\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data_set, train_step,batch_size, cur_index):\n",
    "    \n",
    "    #data_set: [None, time_step, features ]\n",
    "    #batch_idx: index of batch start point\n",
    "    assert(len(data_set) < cur_index+batch_size, \"batch index out of range\")\n",
    "    batch =  data_set[cur_index:cur_index + batch_size, :, :]\n",
    "    train, label = np.split(batch, [train_step], axis=1)\n",
    "    label = label[:,:,-1]\n",
    "    return train, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 12, 4) (50, 5)\n",
      "[[[ 30.41  30.53  30.18  30.45]\n",
      "  [ 30.84  30.84  30.25  30.33]\n",
      "  [ 30.76  30.8   30.14  30.45]\n",
      "  ..., \n",
      "  [ 30.33  30.53  30.02  30.45]\n",
      "  [ 30.29  30.49  30.22  30.41]\n",
      "  [ 30.29  30.57  30.06  30.45]]\n",
      "\n",
      " [[ 30.84  30.84  30.25  30.33]\n",
      "  [ 30.76  30.8   30.14  30.45]\n",
      "  [ 30.53  30.53  30.18  30.37]\n",
      "  ..., \n",
      "  [ 30.29  30.49  30.22  30.41]\n",
      "  [ 30.29  30.57  30.06  30.45]\n",
      "  [ 30.37  30.64  30.18  30.53]]\n",
      "\n",
      " [[ 30.76  30.8   30.14  30.45]\n",
      "  [ 30.53  30.53  30.18  30.37]\n",
      "  [ 30.37  30.53  29.82  30.06]\n",
      "  ..., \n",
      "  [ 30.29  30.57  30.06  30.45]\n",
      "  [ 30.37  30.64  30.18  30.53]\n",
      "  [ 30.53  30.88  30.37  30.64]]\n",
      "\n",
      " ..., \n",
      " [[ 34.74  34.74  33.84  34.12]\n",
      "  [ 33.71  34.08  33.67  33.67]\n",
      "  [ 33.67  33.96  33.26  33.51]\n",
      "  ..., \n",
      "  [ 34.66  35.27  34.53  34.99]\n",
      "  [ 35.32  36.14  35.23  35.85]\n",
      "  [ 35.56  37.45  35.56  35.81]]\n",
      "\n",
      " [[ 33.71  34.08  33.67  33.67]\n",
      "  [ 33.67  33.96  33.26  33.51]\n",
      "  [ 33.51  33.71  33.22  33.71]\n",
      "  ..., \n",
      "  [ 35.32  36.14  35.23  35.85]\n",
      "  [ 35.56  37.45  35.56  35.81]\n",
      "  [ 36.51  37.45  36.3   36.96]]\n",
      "\n",
      " [[ 33.67  33.96  33.26  33.51]\n",
      "  [ 33.51  33.71  33.22  33.71]\n",
      "  [ 33.06  33.71  33.06  33.71]\n",
      "  ..., \n",
      "  [ 35.56  37.45  35.56  35.81]\n",
      "  [ 36.51  37.45  36.3   36.96]\n",
      "  [ 37.53  38.19  37.53  37.78]]]\n"
     ]
    }
   ],
   "source": [
    "batch, label = get_batch(train_set, 12,50, 20)\n",
    "print(np.shape(batch), np.shape(label))\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:37,  2.66it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:40,  2.45it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:01<00:45,  2.13it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:02<00:48,  1.98it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:02<00:44,  2.13it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:03<00:48,  1.96it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:03<00:46,  2.00it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:04<00:46,  2.00it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:04<00:49,  1.84it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:04<00:42,  2.12it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:05<00:44,  1.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 886.5277099609375:  11%|█         | 11/100 [00:06<00:44,  1.99it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  12%|█▏        | 12/100 [00:06<01:04,  1.36it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  13%|█▎        | 13/100 [00:07<01:00,  1.43it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  14%|█▍        | 14/100 [00:07<00:50,  1.71it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  15%|█▌        | 15/100 [00:08<00:50,  1.69it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  16%|█▌        | 16/100 [00:08<00:49,  1.69it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  17%|█▋        | 17/100 [00:09<00:43,  1.90it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  18%|█▊        | 18/100 [00:09<00:45,  1.81it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  19%|█▉        | 19/100 [00:10<00:42,  1.90it/s]\u001b[A\n",
      "train l2loss: 886.5277099609375:  20%|██        | 20/100 [00:10<00:42,  1.89it/s]\u001b[A\n",
      "val l2loss: 1217.6644287109375:  20%|██        | 20/100 [00:11<00:42,  1.89it/s] \u001b[A\n",
      "val l2loss: 1217.6644287109375:  21%|██        | 21/100 [00:11<00:45,  1.74it/s]\u001b[A\n",
      "val l2loss: 1217.6644287109375:  22%|██▏       | 22/100 [00:11<00:38,  2.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 827.4632568359375:  22%|██▏       | 22/100 [00:13<00:38,  2.00it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  23%|██▎       | 23/100 [00:13<00:52,  1.47it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  24%|██▍       | 24/100 [00:13<00:46,  1.63it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  25%|██▌       | 25/100 [00:14<00:46,  1.62it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  26%|██▌       | 26/100 [00:14<00:39,  1.85it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  27%|██▋       | 27/100 [00:15<00:40,  1.81it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  28%|██▊       | 28/100 [00:15<00:41,  1.74it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  29%|██▉       | 29/100 [00:16<00:34,  2.03it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  30%|███       | 30/100 [00:16<00:36,  1.93it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  31%|███       | 31/100 [00:17<00:37,  1.86it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  32%|███▏      | 32/100 [00:17<00:31,  2.15it/s]\u001b[A\n",
      "train l2loss: 827.4632568359375:  33%|███▎      | 33/100 [00:18<00:33,  2.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 862.3818359375:  33%|███▎      | 33/100 [00:19<00:33,  2.01it/s]   \u001b[A\n",
      "train l2loss: 862.3818359375:  34%|███▍      | 34/100 [00:19<00:43,  1.52it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  35%|███▌      | 35/100 [00:19<00:41,  1.56it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  36%|███▌      | 36/100 [00:19<00:34,  1.84it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  37%|███▋      | 37/100 [00:20<00:35,  1.78it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  38%|███▊      | 38/100 [00:21<00:36,  1.72it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  39%|███▉      | 39/100 [00:21<00:30,  2.00it/s]\u001b[A\n",
      "train l2loss: 862.3818359375:  40%|████      | 40/100 [00:22<00:31,  1.89it/s]\u001b[A\n",
      "val l2loss: 1125.053466796875:  40%|████      | 40/100 [00:22<00:31,  1.89it/s]\u001b[A\n",
      "val l2loss: 1125.053466796875:  41%|████      | 41/100 [00:22<00:31,  1.86it/s]\u001b[A\n",
      "val l2loss: 1125.053466796875:  42%|████▏     | 42/100 [00:23<00:30,  1.92it/s]\u001b[A\n",
      "val l2loss: 1125.053466796875:  43%|████▎     | 43/100 [00:23<00:31,  1.81it/s]\u001b[A\n",
      "val l2loss: 1125.053466796875:  44%|████▍     | 44/100 [00:24<00:26,  2.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [44]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 767.1021118164062:  44%|████▍     | 44/100 [00:25<00:26,  2.09it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  45%|████▌     | 45/100 [00:25<00:36,  1.52it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  46%|████▌     | 46/100 [00:25<00:30,  1.77it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  47%|████▋     | 47/100 [00:26<00:30,  1.76it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  48%|████▊     | 48/100 [00:26<00:29,  1.75it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  49%|████▉     | 49/100 [00:27<00:25,  2.00it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  50%|█████     | 50/100 [00:27<00:26,  1.89it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  51%|█████     | 51/100 [00:28<00:25,  1.91it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  52%|█████▏    | 52/100 [00:28<00:25,  1.90it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  53%|█████▎    | 53/100 [00:29<00:25,  1.84it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  54%|█████▍    | 54/100 [00:29<00:22,  2.08it/s]\u001b[A\n",
      "train l2loss: 767.1021118164062:  55%|█████▌    | 55/100 [00:30<00:23,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 804.4862060546875:  55%|█████▌    | 55/100 [00:31<00:23,  1.88it/s]\u001b[A\n",
      "train l2loss: 804.4862060546875:  56%|█████▌    | 56/100 [00:31<00:31,  1.38it/s]\u001b[A\n",
      "train l2loss: 804.4862060546875:  57%|█████▋    | 57/100 [00:32<00:29,  1.45it/s]\u001b[A\n",
      "train l2loss: 804.4862060546875:  58%|█████▊    | 58/100 [00:32<00:25,  1.64it/s]\u001b[A\n",
      "train l2loss: 804.4862060546875:  59%|█████▉    | 59/100 [00:33<00:24,  1.64it/s]\u001b[A\n",
      "train l2loss: 804.4862060546875:  60%|██████    | 60/100 [00:33<00:22,  1.75it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  60%|██████    | 60/100 [00:33<00:22,  1.75it/s] \u001b[A\n",
      "val l2loss: 1077.3382568359375:  61%|██████    | 61/100 [00:33<00:20,  1.93it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  62%|██████▏   | 62/100 [00:34<00:20,  1.82it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  63%|██████▎   | 63/100 [00:34<00:18,  1.98it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  64%|██████▍   | 64/100 [00:35<00:19,  1.88it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  65%|██████▌   | 65/100 [00:36<00:19,  1.79it/s]\u001b[A\n",
      "val l2loss: 1077.3382568359375:  66%|██████▌   | 66/100 [00:36<00:16,  2.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 745.4552001953125:  66%|██████▌   | 66/100 [00:37<00:16,  2.02it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  67%|██████▋   | 67/100 [00:37<00:22,  1.44it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  68%|██████▊   | 68/100 [00:38<00:21,  1.46it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  69%|██████▉   | 69/100 [00:38<00:20,  1.52it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  70%|███████   | 70/100 [00:39<00:17,  1.72it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  71%|███████   | 71/100 [00:39<00:17,  1.67it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  72%|███████▏  | 72/100 [00:40<00:15,  1.86it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  73%|███████▎  | 73/100 [00:40<00:14,  1.87it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  74%|███████▍  | 74/100 [00:41<00:14,  1.80it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  75%|███████▌  | 75/100 [00:41<00:12,  1.99it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  76%|███████▌  | 76/100 [00:42<00:13,  1.84it/s]\u001b[A\n",
      "train l2loss: 745.4552001953125:  77%|███████▋  | 77/100 [00:43<00:12,  1.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 702.4982299804688:  77%|███████▋  | 77/100 [00:44<00:12,  1.85it/s]\u001b[A\n",
      "train l2loss: 702.4982299804688:  78%|███████▊  | 78/100 [00:44<00:15,  1.46it/s]\u001b[A\n",
      "train l2loss: 702.4982299804688:  79%|███████▉  | 79/100 [00:44<00:12,  1.72it/s]\u001b[A\n",
      "train l2loss: 702.4982299804688:  80%|████████  | 80/100 [00:44<00:11,  1.73it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  80%|████████  | 80/100 [00:45<00:11,  1.73it/s] \u001b[A\n",
      "val l2loss: 1036.9993896484375:  81%|████████  | 81/100 [00:45<00:11,  1.67it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  82%|████████▏ | 82/100 [00:46<00:09,  1.88it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  83%|████████▎ | 83/100 [00:46<00:09,  1.81it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  84%|████████▍ | 84/100 [00:47<00:08,  1.87it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  85%|████████▌ | 85/100 [00:47<00:07,  1.96it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  86%|████████▌ | 86/100 [00:48<00:07,  1.84it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  87%|████████▋ | 87/100 [00:48<00:06,  2.02it/s]\u001b[A\n",
      "val l2loss: 1036.9993896484375:  88%|████████▊ | 88/100 [00:49<00:06,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 686.0328369140625:  88%|████████▊ | 88/100 [00:50<00:06,  1.86it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  89%|████████▉ | 89/100 [00:50<00:08,  1.34it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  90%|█████████ | 90/100 [00:51<00:07,  1.42it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  91%|█████████ | 91/100 [00:51<00:05,  1.74it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  92%|█████████▏| 92/100 [00:51<00:04,  1.70it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  93%|█████████▎| 93/100 [00:52<00:04,  1.69it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  94%|█████████▍| 94/100 [00:52<00:03,  1.87it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  95%|█████████▌| 95/100 [00:53<00:02,  1.82it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  96%|█████████▌| 96/100 [00:53<00:02,  1.93it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  97%|█████████▋| 97/100 [00:54<00:01,  1.92it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  98%|█████████▊| 98/100 [00:55<00:01,  1.84it/s]\u001b[A\n",
      "train l2loss: 686.0328369140625:  99%|█████████▉| 99/100 [00:55<00:00,  2.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Saving checkpoints...step: [99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train l2loss: 623.392578125:  99%|█████████▉| 99/100 [00:56<00:00,  2.09it/s]    \u001b[A\n",
      "train l2loss: 623.392578125: 100%|██████████| 100/100 [00:56<00:00,  1.46it/s]\u001b[A\n",
      "val l2loss: 1002.7181396484375: 100%|██████████| 100/100 [00:56<00:00,  1.46it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "def save_ckpt(saver:tf.train.Saver(), sess, checkpoint_dir, ckpt_name, step):\n",
    "    \n",
    "    print(\" [*] Saving checkpoints...step: [{}]\".format(step))\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "    saver.save(sess, \n",
    "               os.path.join(checkpoint_dir, ckpt_name),\n",
    "               global_step=step)\n",
    "    \n",
    "from tqdm import tqdm\n",
    "checkpoint_dir = './model/forfun'\n",
    "ckpt_name = 'toy'\n",
    "\n",
    "pbar = tqdm(total=100)\n",
    "init = tf.global_variables_initializer()  \n",
    "epoch = 0\n",
    "Nepoch = 100\n",
    "pbar = tqdm(total=Nepoch)\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    while epoch < Nepoch:\n",
    "        \n",
    "        epoch += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "        np.random.shuffle(train_set)\n",
    "        Nbatch = len(train_set)//batch_size\n",
    "        \n",
    "        for i in range(Nbatch):         \n",
    "            batch_index = i*batch_size\n",
    "            train_data, label = get_batch(train_set, train_step, batch_size, batch_index)\n",
    "            _ =  sess.run(train_op, feed_dict={x:train_data, y:label})\n",
    "       \n",
    "        if epoch%11 == 0:\n",
    "            l2loss, train_sum =  sess.run([loss, merged_summary_train], feed_dict={x:train_data, y:label})\n",
    "            #Save tensorboard\n",
    "            summary_writer.add_summary(train_sum, epoch)\n",
    "            #Save ckpt\n",
    "            save_ckpt(saver, sess, checkpoint_dir, ckpt_name, epoch)\n",
    "            pbar.set_description('train l2loss: {}'.format(l2loss))       \n",
    "            \n",
    "            \n",
    "            \n",
    "        if epoch%20 == 0:\n",
    "            val_data, val_label = get_batch(test_set, train_step, batch_size, 0)\n",
    "            l2loss, val_sum =  sess.run([loss, merged_summary_val], feed_dict={x:val_data, y:val_label})\n",
    "            #Save tensorboard\n",
    "            summary_writer.add_summary(val_sum, epoch)\n",
    "            pbar.set_description('val l2loss: {}'.format(l2loss))\n",
    "    \n",
    "    \n",
    "    out, state= sess.run([dec, raw_dec], feed_dict={x:val_data})\n",
    "    '''\n",
    "    for i in range(50):\n",
    "        l2loss,_ =  sess.run([loss, train_op], feed_dict={x:train, y:test})\n",
    "        print('l2loss: {}'.format(l2loss))\n",
    "    \n",
    "    print_c('============================')\n",
    "    print_c('{},{}'.format(np.shape(out), np.shape(state)))\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 5) (16, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(out), np.shape(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43c8f0a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/IwVfmOM8TNW+I0xxs9Y4TfGGD/z/wFyVmtomhllKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43c91aac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(out[0,:])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(val_label[0,:])\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
